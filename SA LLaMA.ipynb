{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0vddrvvM461"
      },
      "source": [
        "# SA LLaMA"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installations for colab\n",
        "!pip install huggingface_hub transformers torch accelerate bitsandbytes sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mxDTEam3NAI5",
        "outputId": "8a5785ba-62b5-47fd-bcd7-7a4d0e973956"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (0.26.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (0.45.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AqQ-G004M464"
      },
      "outputs": [],
      "source": [
        "# huggingface login necessary because llama is gated\n",
        "# token should be invalidated and refreshed after every git commit\n",
        "from huggingface_hub import login\n",
        "login(token=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "B6duZ_GzM467",
        "outputId": "fe7d28f2-cf43-40e2-9cbf-162fb17fbb07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0           created_at file_name  followers  friends group_name  \\\n",
              "0           0  2020-07-12 09:24:26       AMD         25      114        AMD   \n",
              "1           1  2020-07-12 08:16:45       AMD       1719        1        AMD   \n",
              "2           2  2020-07-12 08:11:41       AMD         69      135        AMD   \n",
              "3           3  2020-07-12 02:22:50       AMD         34      155        AMD   \n",
              "4           4  2020-07-11 23:58:44       AMD        802      730        AMD   \n",
              "\n",
              "          location  retweet_count      screenname search_query  \\\n",
              "0   United Kingdom            0.0   moffphcgaming         #AMD   \n",
              "1     digitalocean            1.0     LinuxDreams         #AMD   \n",
              "2        Amsterdam            1.0    LinuxReviews         #AMD   \n",
              "3    San Francisco            0.0     NdrewGarcia         #AMD   \n",
              "4  New Jersey, USA            0.0  Roger_Clinton1         #AMD   \n",
              "\n",
              "                                                text    twitter_id  \\\n",
              "0  Been on holiday so back now. Gonna try get som...  1.282244e+18   \n",
              "1  RT @LinuxReviews: #Linux architect Linus Torva...  1.282227e+18   \n",
              "2  #Linux architect Linus Torvalds: AVX512 Is \"A ...  1.282226e+18   \n",
              "3  #AMD stuck in a range box chart https://t.co/5...  1.282138e+18   \n",
              "4  $AMD Epyc Milan Leak â€“ Three early Genesis sam...  1.282102e+18   \n",
              "\n",
              "               username  polarity partition_0 partition_1  sentiment  \n",
              "0      ðŸ•¹MoffPHC GamingðŸ•¹   -0.3102  Technology         AMD          0  \n",
              "1           LinuxDreams   -0.3612  Technology         AMD          0  \n",
              "2          LinuxReviews   -0.3612  Technology         AMD          0  \n",
              "3            Encino_Man   -0.2500  Technology         AMD          0  \n",
              "4  Roger Ocasio-Clinton   -0.3400  Technology         AMD          0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e6d515cd-b1ff-4f44-946e-b83643396537\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>created_at</th>\n",
              "      <th>file_name</th>\n",
              "      <th>followers</th>\n",
              "      <th>friends</th>\n",
              "      <th>group_name</th>\n",
              "      <th>location</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>screenname</th>\n",
              "      <th>search_query</th>\n",
              "      <th>text</th>\n",
              "      <th>twitter_id</th>\n",
              "      <th>username</th>\n",
              "      <th>polarity</th>\n",
              "      <th>partition_0</th>\n",
              "      <th>partition_1</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020-07-12 09:24:26</td>\n",
              "      <td>AMD</td>\n",
              "      <td>25</td>\n",
              "      <td>114</td>\n",
              "      <td>AMD</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>0.0</td>\n",
              "      <td>moffphcgaming</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>Been on holiday so back now. Gonna try get som...</td>\n",
              "      <td>1.282244e+18</td>\n",
              "      <td>ðŸ•¹MoffPHC GamingðŸ•¹</td>\n",
              "      <td>-0.3102</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-07-12 08:16:45</td>\n",
              "      <td>AMD</td>\n",
              "      <td>1719</td>\n",
              "      <td>1</td>\n",
              "      <td>AMD</td>\n",
              "      <td>digitalocean</td>\n",
              "      <td>1.0</td>\n",
              "      <td>LinuxDreams</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>RT @LinuxReviews: #Linux architect Linus Torva...</td>\n",
              "      <td>1.282227e+18</td>\n",
              "      <td>LinuxDreams</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-07-12 08:11:41</td>\n",
              "      <td>AMD</td>\n",
              "      <td>69</td>\n",
              "      <td>135</td>\n",
              "      <td>AMD</td>\n",
              "      <td>Amsterdam</td>\n",
              "      <td>1.0</td>\n",
              "      <td>LinuxReviews</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>#Linux architect Linus Torvalds: AVX512 Is \"A ...</td>\n",
              "      <td>1.282226e+18</td>\n",
              "      <td>LinuxReviews</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-07-12 02:22:50</td>\n",
              "      <td>AMD</td>\n",
              "      <td>34</td>\n",
              "      <td>155</td>\n",
              "      <td>AMD</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NdrewGarcia</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>#AMD stuck in a range box chart https://t.co/5...</td>\n",
              "      <td>1.282138e+18</td>\n",
              "      <td>Encino_Man</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-07-11 23:58:44</td>\n",
              "      <td>AMD</td>\n",
              "      <td>802</td>\n",
              "      <td>730</td>\n",
              "      <td>AMD</td>\n",
              "      <td>New Jersey, USA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Roger_Clinton1</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>$AMD Epyc Milan Leak â€“ Three early Genesis sam...</td>\n",
              "      <td>1.282102e+18</td>\n",
              "      <td>Roger Ocasio-Clinton</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6d515cd-b1ff-4f44-946e-b83643396537')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e6d515cd-b1ff-4f44-946e-b83643396537 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e6d515cd-b1ff-4f44-946e-b83643396537');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3ae3299-a9d6-4fe7-8624-eb316c32a7f7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3ae3299-a9d6-4fe7-8624-eb316c32a7f7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3ae3299-a9d6-4fe7-8624-eb316c32a7f7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_tweets_bigtech_10k_sample",
              "summary": "{\n  \"name\": \"df_tweets_bigtech_10k_sample\",\n  \"rows\": 9500,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2742,\n        \"min\": 0,\n        \"max\": 9499,\n        \"num_unique_values\": 9500,\n        \"samples\": [\n          952,\n          6599,\n          4220\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 8829,\n        \"samples\": [\n          \"2020-07-25 01:29:24\",\n          \"2020-08-10 12:50:24\",\n          \"2020-07-09 09:43:06\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Microsoft\",\n          \"Apple\",\n          \"Netflix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"followers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 116312,\n        \"min\": 0,\n        \"max\": 9652456,\n        \"num_unique_values\": 3625,\n        \"samples\": [\n          22414,\n          1103,\n          2868\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"friends\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10662,\n        \"min\": 0,\n        \"max\": 372886,\n        \"num_unique_values\": 2961,\n        \"samples\": [\n          496,\n          2870,\n          11447\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Microsoft\",\n          \"Apple\",\n          \"Netflix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3845,\n        \"samples\": [\n          \"Newcastle man!\",\n          \"Jakarta Capital Region\",\n          \"Swede living in Dallas, Texas\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2611.342263402457,\n        \"min\": 0.0,\n        \"max\": 57441.0,\n        \"num_unique_values\": 340,\n        \"samples\": [\n          366.0,\n          69.0,\n          53.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"screenname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6806,\n        \"samples\": [\n          \"GeoffreyEwarwa\",\n          \"TheGothGeek\",\n          \"FKUJAK1\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"search_query\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"#Microsoft\",\n          \"#Apple OR #Iphone\",\n          \"#Netflix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6871,\n        \"samples\": [\n          \"I WASN\\u2019T WRONG WE ABOUT TO HAVE THE REAL AANG-ZUKO-KATARA LOVE TRIANGLE.   Too bad I\\u2019m gonna have to boycott if they introduce any white cast members. #atla #netflix #BoycottNetflixATLA https://t.co/lJ8OLIhML6\",\n          \"#CSCO P/E more than half of what #Apple has for its P/E.   P/E list #CSCO 15.94 #APPL 34.84 #MSFT 38.49 #TSLA 955.32 #AMD 161.35  #Cisco #StockMarket #stocks #RobinHood #TikTok #trading #TradingView #NASDAQ #dow\",\n          \"These 4 guys telling us their sob stories and diverting any question.  Regulation is most probably coming.  #Facebook #Google #Apple #amazon #techtestimony https://t.co/7Ql02JsRDd\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"twitter_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4221082858445790.0,\n        \"min\": 1.2806573816183112e+18,\n        \"max\": 1.3017230211708068e+18,\n        \"num_unique_values\": 9063,\n        \"samples\": [\n          1.2832677091076137e+18,\n          1.296138427360936e+18,\n          1.2821971508650598e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 6782,\n        \"samples\": [\n          \"Bike Helmet Pete\",\n          \"Jonathan Linat\",\n          \"Jukka P.Sepp\\u00e4l\\u00e4\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4706186096172633,\n        \"min\": -0.9761,\n        \"max\": 0.9734,\n        \"num_unique_values\": 1218,\n        \"samples\": [\n          -0.5365,\n          -0.4768,\n          -0.7096\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition_0\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Technology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Microsoft\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df_tweets_bigtech_10k_sample = pd.read_csv(\"./tweets_bigtech_10ksample.csv\")\n",
        "\n",
        "df_tweets_bigtech_10k_sample.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "uVCt2mFxM468"
      },
      "outputs": [],
      "source": [
        "df_tweets_bigtech_10k_sample.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "446feaa33e424bc2976e09cfcfa94a16",
            "c65e5bcf6d1340b2a98995df2a1ce074",
            "4d17a740935448318fe30733641b6b62",
            "13e32fc0a8b3490aabd703894bc03522",
            "050f40004a5d4fdaa866b61619c448b2",
            "6325c08c008f435a8a412546cb68be80",
            "474a7beabc494acea0d5755d69ef7f05",
            "052283b622eb499cb2148ce005f12524",
            "59d76d16d10c46be8dece8ea121decd3",
            "8e0a577108eb42e1bcc78442dc7b7721",
            "eaae1889578e4f668a0e03b2a1a40ebb"
          ]
        },
        "id": "wF4ZtkgPM468",
        "outputId": "08b2bde8-cc5d-49cb-c800-4d8e38e3042b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "446feaa33e424bc2976e09cfcfa94a16"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of LlamaForSequenceClassification were not initialized from the model checkpoint at meta-llama/Llama-2-7b-chat-hf and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name,\n",
        "    load_in_8bit=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        "    llm_int8_enable_fp32_cpu_offload=True\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "pipeline = transformers.pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    torch_dtype=torch.float16,\n",
        "    device_map=\"auto\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline(\"The new Iphone is not good.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3GvXcpLPyxs",
        "outputId": "40259550-2ee1-439c-e069-2beb4091ff60"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'LABEL_0', 'score': 0.8708171844482422}]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets_bigtech_10k_sample[\"predicted_sentiment\"] = df_tweets_bigtech_10k_sample[\"text\"].apply(lambda x: pipeline(x)[0][\"label\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3tCBzgNTR8H",
        "outputId": "c0437480-2c8a-46eb-b804-03cd9015cc61"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets_bigtech_10k_sample[\"predicted_sentiment\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "9xDfTIj3VcAO",
        "outputId": "b70484e6-3672-46d0-d0f6-19c3a967ed88"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "predicted_sentiment\n",
              "LABEL_1    8313\n",
              "LABEL_0    1187\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>LABEL_1</th>\n",
              "      <td>8313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LABEL_0</th>\n",
              "      <td>1187</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# adapting predicted labels to fit format\n",
        "df_tweets_bigtech_10k_sample[\"predicted_sentiment\"] = df_tweets_bigtech_10k_sample[\"predicted_sentiment\"].apply(lambda x: 2 if x == \"LABEL_1\" else 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlDq2WB_dgkl",
        "outputId": "bc224e5f-3aaa-4f3d-d9f3-d918fdf26944"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-38-53d60b99633f>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_tweets_bigtech_10k_sample[\"predicted_sentiment\"] = df_tweets_bigtech_10k_sample[\"predicted_sentiment\"].apply(lambda x: 1 if x == \"LABEL_1\" else 0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# removing neutral tweets, since model only predicted negative and positive\n",
        "df_tweets_bigtech_10k_sample = df_tweets_bigtech_10k_sample[df_tweets_bigtech_10k_sample[\"sentiment\"] != 1]"
      ],
      "metadata": {
        "id": "lcvj8HLEdFHc"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets_bigtech_10k_sample.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "id": "2npHyGVldTS-",
        "outputId": "37524ecb-0c0c-40cd-929a-0c8eb9c05f31"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0           created_at file_name  followers  friends group_name  \\\n",
              "0           0  2020-07-12 09:24:26       AMD         25      114        AMD   \n",
              "1           1  2020-07-12 08:16:45       AMD       1719        1        AMD   \n",
              "2           2  2020-07-12 08:11:41       AMD         69      135        AMD   \n",
              "3           3  2020-07-12 02:22:50       AMD         34      155        AMD   \n",
              "4           4  2020-07-11 23:58:44       AMD        802      730        AMD   \n",
              "\n",
              "          location  retweet_count      screenname search_query  \\\n",
              "0   United Kingdom            0.0   moffphcgaming         #AMD   \n",
              "1     digitalocean            1.0     LinuxDreams         #AMD   \n",
              "2        Amsterdam            1.0    LinuxReviews         #AMD   \n",
              "3    San Francisco            0.0     NdrewGarcia         #AMD   \n",
              "4  New Jersey, USA            0.0  Roger_Clinton1         #AMD   \n",
              "\n",
              "                                                text    twitter_id  \\\n",
              "0  Been on holiday so back now. Gonna try get som...  1.282244e+18   \n",
              "1  RT @LinuxReviews: #Linux architect Linus Torva...  1.282227e+18   \n",
              "2  #Linux architect Linus Torvalds: AVX512 Is \"A ...  1.282226e+18   \n",
              "3  #AMD stuck in a range box chart https://t.co/5...  1.282138e+18   \n",
              "4  $AMD Epyc Milan Leak â€“ Three early Genesis sam...  1.282102e+18   \n",
              "\n",
              "               username  polarity partition_0 partition_1  sentiment  \\\n",
              "0      ðŸ•¹MoffPHC GamingðŸ•¹   -0.3102  Technology         AMD          0   \n",
              "1           LinuxDreams   -0.3612  Technology         AMD          0   \n",
              "2          LinuxReviews   -0.3612  Technology         AMD          0   \n",
              "3            Encino_Man   -0.2500  Technology         AMD          0   \n",
              "4  Roger Ocasio-Clinton   -0.3400  Technology         AMD          0   \n",
              "\n",
              "   predicted_sentiment  \n",
              "0                    2  \n",
              "1                    0  \n",
              "2                    2  \n",
              "3                    2  \n",
              "4                    2  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a46eadba-ac8e-4e92-b2ca-aac3b0e9ad64\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>created_at</th>\n",
              "      <th>file_name</th>\n",
              "      <th>followers</th>\n",
              "      <th>friends</th>\n",
              "      <th>group_name</th>\n",
              "      <th>location</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>screenname</th>\n",
              "      <th>search_query</th>\n",
              "      <th>text</th>\n",
              "      <th>twitter_id</th>\n",
              "      <th>username</th>\n",
              "      <th>polarity</th>\n",
              "      <th>partition_0</th>\n",
              "      <th>partition_1</th>\n",
              "      <th>sentiment</th>\n",
              "      <th>predicted_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>2020-07-12 09:24:26</td>\n",
              "      <td>AMD</td>\n",
              "      <td>25</td>\n",
              "      <td>114</td>\n",
              "      <td>AMD</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>0.0</td>\n",
              "      <td>moffphcgaming</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>Been on holiday so back now. Gonna try get som...</td>\n",
              "      <td>1.282244e+18</td>\n",
              "      <td>ðŸ•¹MoffPHC GamingðŸ•¹</td>\n",
              "      <td>-0.3102</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2020-07-12 08:16:45</td>\n",
              "      <td>AMD</td>\n",
              "      <td>1719</td>\n",
              "      <td>1</td>\n",
              "      <td>AMD</td>\n",
              "      <td>digitalocean</td>\n",
              "      <td>1.0</td>\n",
              "      <td>LinuxDreams</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>RT @LinuxReviews: #Linux architect Linus Torva...</td>\n",
              "      <td>1.282227e+18</td>\n",
              "      <td>LinuxDreams</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2020-07-12 08:11:41</td>\n",
              "      <td>AMD</td>\n",
              "      <td>69</td>\n",
              "      <td>135</td>\n",
              "      <td>AMD</td>\n",
              "      <td>Amsterdam</td>\n",
              "      <td>1.0</td>\n",
              "      <td>LinuxReviews</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>#Linux architect Linus Torvalds: AVX512 Is \"A ...</td>\n",
              "      <td>1.282226e+18</td>\n",
              "      <td>LinuxReviews</td>\n",
              "      <td>-0.3612</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2020-07-12 02:22:50</td>\n",
              "      <td>AMD</td>\n",
              "      <td>34</td>\n",
              "      <td>155</td>\n",
              "      <td>AMD</td>\n",
              "      <td>San Francisco</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NdrewGarcia</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>#AMD stuck in a range box chart https://t.co/5...</td>\n",
              "      <td>1.282138e+18</td>\n",
              "      <td>Encino_Man</td>\n",
              "      <td>-0.2500</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2020-07-11 23:58:44</td>\n",
              "      <td>AMD</td>\n",
              "      <td>802</td>\n",
              "      <td>730</td>\n",
              "      <td>AMD</td>\n",
              "      <td>New Jersey, USA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Roger_Clinton1</td>\n",
              "      <td>#AMD</td>\n",
              "      <td>$AMD Epyc Milan Leak â€“ Three early Genesis sam...</td>\n",
              "      <td>1.282102e+18</td>\n",
              "      <td>Roger Ocasio-Clinton</td>\n",
              "      <td>-0.3400</td>\n",
              "      <td>Technology</td>\n",
              "      <td>AMD</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a46eadba-ac8e-4e92-b2ca-aac3b0e9ad64')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a46eadba-ac8e-4e92-b2ca-aac3b0e9ad64 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a46eadba-ac8e-4e92-b2ca-aac3b0e9ad64');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a285d891-0cbe-4fa2-8863-dd88bdd75466\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a285d891-0cbe-4fa2-8863-dd88bdd75466')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a285d891-0cbe-4fa2-8863-dd88bdd75466 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_tweets_bigtech_10k_sample",
              "summary": "{\n  \"name\": \"df_tweets_bigtech_10k_sample\",\n  \"rows\": 7000,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3165,\n        \"min\": 0,\n        \"max\": 9499,\n        \"num_unique_values\": 7000,\n        \"samples\": [\n          9000,\n          2944,\n          2024\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 6570,\n        \"samples\": [\n          \"2020-07-10 23:50:12\",\n          \"2020-07-08 22:16:52\",\n          \"2020-07-23 09:19:36\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"file_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Microsoft\",\n          \"Apple\",\n          \"Netflix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"followers\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 55473,\n        \"min\": 0,\n        \"max\": 2021667,\n        \"num_unique_values\": 3021,\n        \"samples\": [\n          19640,\n          220,\n          17677\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"friends\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10928,\n        \"min\": 0,\n        \"max\": 372886,\n        \"num_unique_values\": 2526,\n        \"samples\": [\n          5378,\n          602,\n          360\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"group_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Microsoft\",\n          \"Apple\",\n          \"Netflix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2967,\n        \"samples\": [\n          \"London, United Kingdom\",\n          \"At home\",\n          \"South by Southwest\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retweet_count\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2895.52162707255,\n        \"min\": 0.0,\n        \"max\": 57441.0,\n        \"num_unique_values\": 247,\n        \"samples\": [\n          42.0,\n          14.0,\n          72.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"screenname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5168,\n        \"samples\": [\n          \"leoluminary\",\n          \"ark_ritz\",\n          \"foxygames_uk\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"search_query\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"#Microsoft\",\n          \"#Apple OR #Iphone\",\n          \"#Netflix\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5310,\n        \"samples\": [\n          \"Stock gains in 2020  #Zoom: +280% #Nvidia: +276% #Tesla: +247% #Etsy: +205% #Docusign: +176% #Shopify: +173% #Peloton: +140% #Wix: +138% #Square: +135% #Teladoc: +131% #Pinterest: +88% #AMD: +85% #PayPal: +84% #Amazon: +71% #Spotify: +69% #Netflix: +53% #Apple: +51%\",\n          \"Scream: The TV Series - S01E10 - Revelations #NW #ScreamTV #Netflix #PPwatches https://t.co/Gh7ixxCQch\",\n          \"This week on D'Arcade we're all about #CancelCulture. From Netflix dropping shows to video games quietly being disposed of, we have all the dirty deets right here!  https://t.co/aS01J0lDbI  #Netflix #Avengers #ChillingAdventuresofSabrina https://t.co/JZcRn1CYvA\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"twitter_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4525947837397439.0,\n        \"min\": 1.2806573816183112e+18,\n        \"max\": 1.3017230211708068e+18,\n        \"num_unique_values\": 6692,\n        \"samples\": [\n          1.281456558614786e+18,\n          1.2817529369310454e+18,\n          1.2830065863660667e+18\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"username\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5162,\n        \"samples\": [\n          \"Adriano B. Lucatelli\",\n          \"my own person\",\n          \"Juan Luis Rosario Semidey\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"polarity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5477737564685466,\n        \"min\": -0.9761,\n        \"max\": 0.9734,\n        \"num_unique_values\": 1175,\n        \"samples\": [\n          0.4939,\n          -0.8316,\n          -0.658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition_0\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Technology\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"partition_1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"Microsoft\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets_bigtech_10k_sample[\"sentiment\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "qNfwrpzVg2Ix",
        "outputId": "284e0c53-2e43-4ba3-d51a-81ced2fcc87e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "0    3500\n",
              "2    3500\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_tweets_bigtech_10k_sample[\"predicted_sentiment\"].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "9pg0dpGGg3JN",
        "outputId": "a46f4725-2926-46e7-97fc-52c3375e7ad4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "predicted_sentiment\n",
              "2    6021\n",
              "0     979\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>predicted_sentiment</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>979</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "def performance_metrics(df, label, prediction):\n",
        "     accuracy = accuracy_score(df[label], df[prediction])\n",
        "     precision = precision_score(df[label], df[prediction], average=\"weighted\")\n",
        "     recall = recall_score(df[label], df[prediction], average=\"weighted\")\n",
        "     f1 = f1_score(df[label], df[prediction], average=\"weighted\")\n",
        "\n",
        "     print(f\"Accuracy: {accuracy}\")\n",
        "     print(f\"Precision: {precision}\")\n",
        "     print(f\"Recall: {recall}\")\n",
        "     print(f\"F1-Score: {f1}\")\n",
        "\n",
        "performance_metrics(df_tweets_bigtech_10k_sample, \"sentiment\", \"predicted_sentiment\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20BOTO0saLVy",
        "outputId": "96ff0df8-d217-434f-d054-ef451f1b0e43"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5095714285714286\n",
            "Precision: 0.5198912251111576\n",
            "Recall: 0.5095714285714286\n",
            "F1-Score: 0.43648145124446003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "913debcebd5a44299c6f9766949b6115"
          ]
        },
        "id": "nHsvqYWlM469",
        "outputId": "5fa82c14-a0ad-46c6-cc24-b298b3e8a6fe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "913debcebd5a44299c6f9766949b6115",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
        "from accelerate import infer_auto_device_map, dispatch_model\n",
        "import torch\n",
        "\n",
        "# Define the model name\n",
        "model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "\n",
        "# Load the model with disk offloading\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from accelerate import infer_auto_device_map, dispatch_model\n",
        "\n",
        "# Load the model with empty weights to prevent full memory load\n",
        "from accelerate import init_empty_weights\n",
        "\n",
        "with init_empty_weights():\n",
        "    model_instance = AutoModelForSequenceClassification.from_pretrained(model)\n",
        "\n",
        "# Define device map for offloading\n",
        "device_map = infer_auto_device_map(model_instance, no_split_module_classes=[\"LlamaDecoderLayer\"], offload_folder=\"offload_dir\")\n",
        "\n",
        "# Dispatch the model to the devices (including disk offload)\n",
        "model_instance = dispatch_model(model_instance, device_map=device_map, offload_folder=\"offload_dir\")\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = pipeline(\n",
        "    \"text-classification\",  # Task type; \"sentiment-analysis\" maps to \"text-classification\"\n",
        "    model=model_instance,\n",
        "    tokenizer=tokenizer,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16#,\n",
        "    #load_in_8bit=True\n",
        ")\n",
        "\n",
        "# Use the pipeline\n",
        "input_text = \"I love this product!\"\n",
        "output = pipeline(input_text)\n",
        "print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fWSSPN40M469",
        "outputId": "517ad906-d6d9-44f6-9c3d-01c3b65e3984"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
            "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m init_empty_weights\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m init_empty_weights():\n\u001b[1;32m---> 15\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Step 3: Define the device map with disk offloading\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maccelerate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m infer_auto_device_map\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:3669\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3666\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3669\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3675\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3676\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[0;32m   3677\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_8bit.py:81\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[0;32m     80\u001b[0m bnb_multibackend_is_enabled \u001b[38;5;241m=\u001b[39m is_bitsandbytes_multi_backend_available()\n\u001b[1;32m---> 81\u001b[0m \u001b[43mvalidate_bnb_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:558\u001b[0m, in \u001b[0;36mvalidate_bnb_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_multi_backend_available():\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_multi_backend_availability(raise_exception)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_validate_bnb_cuda_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:536\u001b[0m, in \u001b[0;36m_validate_bnb_cuda_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exception:\n\u001b[0;32m    535\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(log_msg)\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(log_msg)\n\u001b[0;32m    538\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(log_msg)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from accelerate import init_empty_weights, infer_auto_device_map, dispatch_model\n",
        "\n",
        "# Define model name and offload directory\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "offload_folder = \"offload_dir\"  # Directory for offloading to disk (ensure it exists and has sufficient space)\n",
        "\n",
        "# Step 1: Initialize tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Step 2: Initialize model with empty weights\n",
        "from accelerate import init_empty_weights\n",
        "\n",
        "with init_empty_weights():\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name, load_in_8bit=True)\n",
        "\n",
        "# Step 3: Define the device map with disk offloading\n",
        "from accelerate import infer_auto_device_map\n",
        "\n",
        "device_map = infer_auto_device_map(\n",
        "    model,\n",
        "    max_memory={\"cpu\": \"8GB\", \"cuda\": \"8GB\", \"disk\": \"30GB\"},  # Adjust as per your system\n",
        "    no_split_module_classes=[\"LlamaDecoderLayer\"]\n",
        ")\n",
        "\n",
        "# Step 4: Dispatch the model with disk offloading\n",
        "from accelerate import dispatch_model\n",
        "\n",
        "model = dispatch_model(\n",
        "    model,\n",
        "    device_map=device_map,\n",
        "    offload_folder=offload_folder  # Specify the offload directory\n",
        ")\n",
        "\n",
        "# Verify setup\n",
        "print(f\"Model loaded with device map: {device_map}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pp2EQr0IM46-",
        "outputId": "cbd4e879-bf35-41f3-d656-b6a94469f946"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "#pip uninstall bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rtV2KbHM46-",
        "outputId": "9f0b86e3-6be9-4d81-a7bc-90c8a2f5e317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Could not find a version that satisfies the requirement bitsandbytes-cpu (from versions: none)\n",
            "\n",
            "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
            "ERROR: No matching distribution found for bitsandbytes-cpu\n"
          ]
        }
      ],
      "source": [
        "#pip install bitsandbytes-cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Drt46HM0M46-",
        "outputId": "0738b454-b19a-4326-a27c-821271ebd60c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.45.0\n"
          ]
        }
      ],
      "source": [
        "import bitsandbytes as bnb\n",
        "print(bnb.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TBckFdLM46-",
        "outputId": "409851a6-f18a-4d59-f22d-627e6c2ed312"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
            "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[5], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_name)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the model with 8-bit quantization\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Automatically configure for CPU\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Use bitsandbytes for 8-bit quantization\u001b[39;49;00m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Set up the pipeline\u001b[39;00m\n\u001b[0;32m     16\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m pipeline(\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment-analysis\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m     19\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer\n\u001b[0;32m     20\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:564\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    563\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhub_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    569\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    570\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\modeling_utils.py:3669\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3666\u001b[0m     hf_quantizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hf_quantizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 3669\u001b[0m     \u001b[43mhf_quantizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalidate_environment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtorch_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_tf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_tf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfrom_flax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfrom_flax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3673\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweights_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3675\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3676\u001b[0m     torch_dtype \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_torch_dtype(torch_dtype)\n\u001b[0;32m   3677\u001b[0m     device_map \u001b[38;5;241m=\u001b[39m hf_quantizer\u001b[38;5;241m.\u001b[39mupdate_device_map(device_map)\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\quantizers\\quantizer_bnb_8bit.py:81\u001b[0m, in \u001b[0;36mBnb8BitHfQuantizer.validate_environment\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_bitsandbytes_multi_backend_available\n\u001b[0;32m     80\u001b[0m bnb_multibackend_is_enabled \u001b[38;5;241m=\u001b[39m is_bitsandbytes_multi_backend_available()\n\u001b[1;32m---> 81\u001b[0m \u001b[43mvalidate_bnb_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_tf\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_flax\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConverting into 4-bit or 8-bit weights from tf/flax weights is currently not supported, please make\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     86\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m sure the weights are in PyTorch format.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     87\u001b[0m     )\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:558\u001b[0m, in \u001b[0;36mvalidate_bnb_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_bitsandbytes_multi_backend_available():\n\u001b[0;32m    557\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _validate_bnb_multi_backend_availability(raise_exception)\n\u001b[1;32m--> 558\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_validate_bnb_cuda_backend_availability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraise_exception\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\hausb\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\integrations\\bitsandbytes.py:536\u001b[0m, in \u001b[0;36m_validate_bnb_cuda_backend_availability\u001b[1;34m(raise_exception)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m raise_exception:\n\u001b[0;32m    535\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(log_msg)\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(log_msg)\n\u001b[0;32m    538\u001b[0m logger\u001b[38;5;241m.\u001b[39mwarning(log_msg)\n\u001b[0;32m    539\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[1;31mRuntimeError\u001b[0m: CUDA is required but not available for bitsandbytes. Please consider installing the multi-platform enabled version of bitsandbytes, which is currently a work in progress. Please check currently supported platforms and installation instructions at https://huggingface.co/docs/bitsandbytes/main/en/installation#multi-backend"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_name = \"meta-llama/Llama-2-7b-chat-hf\"\n",
        "\n",
        "# Load the tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Load the model with 8-bit quantization\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",  # Automatically configure for CPU\n",
        "    load_in_8bit=True   # Use bitsandbytes for 8-bit quantization\n",
        ")\n",
        "\n",
        "# Set up the pipeline\n",
        "pipeline = pipeline(\n",
        "    \"sentiment-analysis\",\n",
        "    model=model,\n",
        "    tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "# Run inference\n",
        "output = text_pipeline(\"Once upon a time\")\n",
        "print(output)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "446feaa33e424bc2976e09cfcfa94a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c65e5bcf6d1340b2a98995df2a1ce074",
              "IPY_MODEL_4d17a740935448318fe30733641b6b62",
              "IPY_MODEL_13e32fc0a8b3490aabd703894bc03522"
            ],
            "layout": "IPY_MODEL_050f40004a5d4fdaa866b61619c448b2"
          }
        },
        "c65e5bcf6d1340b2a98995df2a1ce074": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6325c08c008f435a8a412546cb68be80",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_474a7beabc494acea0d5755d69ef7f05",
            "value": "Loadingâ€‡checkpointâ€‡shards:â€‡100%"
          }
        },
        "4d17a740935448318fe30733641b6b62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_052283b622eb499cb2148ce005f12524",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59d76d16d10c46be8dece8ea121decd3",
            "value": 2
          }
        },
        "13e32fc0a8b3490aabd703894bc03522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e0a577108eb42e1bcc78442dc7b7721",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_eaae1889578e4f668a0e03b2a1a40ebb",
            "value": "â€‡2/2â€‡[00:53&lt;00:00,â€‡24.37s/it]"
          }
        },
        "050f40004a5d4fdaa866b61619c448b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6325c08c008f435a8a412546cb68be80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "474a7beabc494acea0d5755d69ef7f05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "052283b622eb499cb2148ce005f12524": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59d76d16d10c46be8dece8ea121decd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e0a577108eb42e1bcc78442dc7b7721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaae1889578e4f668a0e03b2a1a40ebb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}